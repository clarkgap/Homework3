{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1\n",
    "\n",
    "The liquid-vapor equilibrium equation with two parameters $A_{12}$ and $A_{21}$:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "P = & x_1\\exp\\left(A_{12}\\left(\\frac{A_{21}x_2}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)P_{water}^{sat}\\\\\n",
    "& + x_2\\exp\\left(A_{21}\\left(\\frac{A_{12}x_1}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)P_{1,4 dioxane}^{sat}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "The saturation pressures, $p^{sat}$ are given by the Antoine equation:\n",
    "\n",
    "$\n",
    "\\log_{10}(P^{sat}) = a_1 - \\frac{a_2}{T + a_3},\n",
    "$\n",
    "\n",
    "where $T = 20$($^{\\circ}{\\rm C}$) and $a_{1,2,3}$ for a water - 1,4 dioxane\n",
    "system is given below.\n",
    "\n",
    "|     &nbsp;  | $a_1$   | $a_2$    | $a_3$   |\n",
    "|:------------|:--------|:---------|:--------|\n",
    "| Water       | 8.07131 | 1730.63  | 233.426 |\n",
    "| 1,4 dioxane | 7.43155 | 1554.679 | 240.337 |\n",
    "\n",
    "\n",
    "The following table lists the measured data. Recall that in a binary system $x_1 + x_2 = 1$, so $x_2=1-x_1$.\n",
    "\n",
    "|$x_1$ | 0.0 | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
    "|:-----|:--------|:---------|:--------|:-----|:-----|:-----|:-----|:-----|:-----|:-----|:-----|\n",
    "|$p$| 28.1 | 34.4 | 36.7 | 36.9 | 36.8 | 36.7 | 36.5 | 35.4 | 32.9 | 27.7 | 17.5 |\n",
    "\n",
    "Estimate $A_{12}$ and $A_{21}$ using data from the above table:\n",
    "\n",
    "### First step, formulating the least square problem.\n",
    "\n",
    "Minimize the total error between expected result and experimental result:\n",
    "\n",
    "$\\underset{A_{12},A_{21}}{\\text{min}}\\sum^{11}_{i=1}(P(x_{1i},A_{12},A_{21})-P_i)^2$\n",
    "\n",
    "Because the independent value is an exponent in an exponential function, the P function is nonlinear with respect to parameters $A_{12}$ and $A_{21}$.\n",
    "\n",
    "Apply gradient descent:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-30-dadb1e9becfb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0mError\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mError\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m**\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mPsw\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mx2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mA\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m**\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mPso\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mPa\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m**\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;31m# no_grad() specifies that the operations within this context are not part of the computational graph, i.e., we don't need the gradient descent algorithm itself to be differentiable with respect to x\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.float64' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x1 = np.linspace(0,1,11)\n",
    "x2 = 1 - x1\n",
    "Pa = np.array([28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5]) # experimental result\n",
    "Psw = 10**(8.07131 - 1730.63/(20+233.426)) # for water\n",
    "Pso = 10**(7.43155 - 1554.679/(20+240.337)) # for 1,4 dioxane\n",
    "\n",
    "A = Variable(t.tensor([1.0, 0.0]), requires_grad=True)\n",
    "\n",
    "# Fix the step size\n",
    "a = 0.01\n",
    "\n",
    "# Start gradient descent\n",
    "for k in range(100):  # TODO: change the termination criterion\n",
    "    for i in range(10):\n",
    "        Error = Error + (x1[i]*math.exp(A[0]*((A[1]*x2[i])/(A[0]*x1[i]+A[1]*x2[i]))**2)*Psw + x2[i]*math.exp(A[1]*((A[0]*x1[i])/(A[0]*x1[i]+A[1]*x2[i]))**2)*Pso - Pa[i])**2\n",
    "    loss = Error\n",
    "    loss.backward()\n",
    "\n",
    "    # no_grad() specifies that the operations within this context are not part of the computational graph, i.e., we don't need the gradient descent algorithm itself to be differentiable with respect to x\n",
    "    with t.no_grad():\n",
    "        A -= a * A.grad\n",
    "\n",
    "        # need to clear the gradient at every step, or otherwise it will accumulate...\n",
    "        A.grad.zero_()\n",
    "\n",
    "print(A.data.numpy())\n",
    "print(loss.data.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "2. Since the model is nonlinear, the problem does not have an analytical solution. Therefore, solve it using the gradient descent or Newton's method implemented in HW1;\n",
    "3. Compare your optimized model with the data. Does your model fit well with the data?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x1 = np.linspace(0,1,11)\n",
    "x2 = 1 - x1\n",
    "Pa = np.array([28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5]) # experimental result\n",
    "Psw = 10**(8.07131 - 1730.63/(20+233.426)) # for water\n",
    "Pso = 10**(7.43155 - 1554.679/(20+240.337)) # for 1,4 dioxane\n",
    "\n",
    "A12 = 2\n",
    "A21 = 3\n",
    "\n",
    "Error = 0\n",
    "for i in range(10):\n",
    "    Error = Error + (x1[i]*math.exp(A12*((A21*x2[i])/(A12*x1[i]+A21*x2[i]))**2)*Psw + x2[i]*math.exp(A21*((A12*x1[i])/(A12*x1[i]+A21*x2[i]))**2)*Pso - Pa[i])**2\n",
    "Loss = Error\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}